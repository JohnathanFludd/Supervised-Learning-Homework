{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>total_bal_ex_mort</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>total_il_high_credit_limit</th>\n",
       "      <th>hardship_flag</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67991</td>\n",
       "      <td>67991</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>814.70</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>97.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>527975.0</td>\n",
       "      <td>70914.0</td>\n",
       "      <td>74600.0</td>\n",
       "      <td>99475.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25429</td>\n",
       "      <td>25429</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>208.70</td>\n",
       "      <td>RENT</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>66.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34628.0</td>\n",
       "      <td>23460.0</td>\n",
       "      <td>5900.0</td>\n",
       "      <td>23628.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38496</td>\n",
       "      <td>38496</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>128.27</td>\n",
       "      <td>RENT</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23100.0</td>\n",
       "      <td>19183.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19667</td>\n",
       "      <td>19667</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>478.33</td>\n",
       "      <td>RENT</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56481.0</td>\n",
       "      <td>43817.0</td>\n",
       "      <td>13800.0</td>\n",
       "      <td>35981.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37505</td>\n",
       "      <td>37505</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>120.27</td>\n",
       "      <td>RENT</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45977.0</td>\n",
       "      <td>32448.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>24977.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index  loan_amnt  int_rate  installment home_ownership  \\\n",
       "0       67991  67991    40000.0    0.0819       814.70       MORTGAGE   \n",
       "1       25429  25429     6000.0    0.1524       208.70           RENT   \n",
       "2       38496  38496     3600.0    0.1695       128.27           RENT   \n",
       "3       19667  19667    20000.0    0.1524       478.33           RENT   \n",
       "4       37505  37505     3600.0    0.1240       120.27           RENT   \n",
       "\n",
       "   annual_inc verification_status loan_status pymnt_plan  ...  pct_tl_nvr_dlq  \\\n",
       "0    140000.0        Not Verified    low_risk          n  ...            97.7   \n",
       "1     55000.0        Not Verified    low_risk          n  ...            66.7   \n",
       "2     42000.0        Not Verified    low_risk          n  ...           100.0   \n",
       "3    100000.0        Not Verified    low_risk          n  ...           100.0   \n",
       "4     50000.0        Not Verified    low_risk          n  ...           100.0   \n",
       "\n",
       "   percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  tot_hi_cred_lim  \\\n",
       "0               0.0                   0.0        0.0         527975.0   \n",
       "1               0.0                   0.0        0.0          34628.0   \n",
       "2               0.0                   0.0        0.0          23100.0   \n",
       "3              50.0                   0.0        0.0          56481.0   \n",
       "4              25.0                   0.0        0.0          45977.0   \n",
       "\n",
       "   total_bal_ex_mort  total_bc_limit total_il_high_credit_limit  \\\n",
       "0            70914.0         74600.0                    99475.0   \n",
       "1            23460.0          5900.0                    23628.0   \n",
       "2            19183.0          7300.0                    15000.0   \n",
       "3            43817.0         13800.0                    35981.0   \n",
       "4            32448.0         21000.0                    24977.0   \n",
       "\n",
       "   hardship_flag  debt_settlement_flag  \n",
       "0              N                     N  \n",
       "1              N                     N  \n",
       "2              N                     N  \n",
       "3              N                     N  \n",
       "4              N                     N  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12175</th>\n",
       "      <td>high_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12176</th>\n",
       "      <td>high_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12177</th>\n",
       "      <td>high_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12178</th>\n",
       "      <td>high_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12179</th>\n",
       "      <td>high_risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12180 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      loan_status\n",
       "0        low_risk\n",
       "1        low_risk\n",
       "2        low_risk\n",
       "3        low_risk\n",
       "4        low_risk\n",
       "...           ...\n",
       "12175   high_risk\n",
       "12176   high_risk\n",
       "12177   high_risk\n",
       "12178   high_risk\n",
       "12179   high_risk\n",
       "\n",
       "[12180 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "X = train_df.drop('loan_status', axis=1)\n",
    "y = train_df[[\"loan_status\"]]\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric and separate target feature for testing data\n",
    "\n",
    "\n",
    "# One-hot encoding the entire dataframe\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "y = y['loan_status'].apply(lambda x: 1 if x == 'high_risk' else 0)\n",
    "type(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1144920\n",
      "12180\n"
     ]
    }
   ],
   "source": [
    "# add missing dummy variables to testing set\n",
    "\n",
    "print(X.size)\n",
    "print(y.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be creating and comparing two models on this data: a logistic regression, and a random forests classifier. Before you create, fit, and score the models, make a prediction as to which model you think will perform better. You do not need to be correct! Write down (in markdown cells in your Jupyter Notebook or in a separate document) your prediction, and provide justification for your educated guess.\n",
    "\n",
    "\n",
    "I believe the random forest model will work better because there are a lot more x values to work with. I believe that using the logistical regression with so many x values might throw off the model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6551724137931034\n",
      "Testing Data Score: 0.6433497536945813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Johna\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.7937602627257799\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False, False,  True, False, False, False, False,\n",
       "        True, False, False, False, False,  True,  True,  True, False,\n",
       "       False,  True,  True,  True, False, False, False, False,  True,\n",
       "        True,  True, False, False,  True,  True,  True, False, False,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "\n",
    "# Create data\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train_scaled, y_train)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')\n",
    "\n",
    "features = clf.feature_importances_\n",
    "#print(features)\n",
    "plt.bar(x = range(len(features)), height=features)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "sel = SelectFromModel(clf)\n",
    "sel.fit(X_train_scaled, y_train)\n",
    "sel.get_support()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a LogisticRegression model, fit it to the data, and print the model's score. Do the same for a RandomForestClassifier. You may choose any starting hyperparameters you like. Which model performed better? How does that compare to your prediction? Write down your results and thoughts.\n",
    "\n",
    "\n",
    "The random forrest model worked better as I predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6851, 36)\n",
      "(9135, 94)\n",
      "(2284, 36)\n",
      "(3045, 94)\n"
     ]
    }
   ],
   "source": [
    "#Scale the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "X_selected_train, X_selected_test, y_selected_train, y_selected_test = train_test_split(sel.transform(X_train), y_train, random_state=1)\n",
    "\n",
    "scaler = StandardScaler().fit(X_selected_train)\n",
    "X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "X_selected_test_scaled = scaler.transform(X_selected_test)\n",
    "\n",
    "\n",
    "print(X_selected_train_scaled.shape)\n",
    "print(X_train.shape)\n",
    "print(X_selected_test_scaled.shape)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7056376573617953\n",
      "Testing Score: 0.7155993431855501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Johna\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "\n",
    "clf = LogisticRegression().fit(X_train_scaled, y_train)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X selected train scaled (6851, 36)\n",
      "X selected test scaled (2284, 36)\n",
      "X train (9135, 94)\n",
      "X test (3045, 94)\n",
      "y train (9135,)\n",
      "y test (3045,)\n",
      "y selected train (6851,)\n",
      "y selected test (2284,)\n",
      "y selected train (6851,)\n",
      "y selected test (2284,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X selected train scaled {X_selected_train_scaled.shape}')\n",
    "print(f'X selected test scaled {X_selected_test_scaled.shape}')\n",
    "\n",
    "print(f'X train {X_train.shape}')\n",
    "print(f'X test {X_test.shape}')\n",
    "\n",
    "print(f'y train {y_train.shape}')\n",
    "print(f'y test {y_test.shape}')\n",
    "\n",
    "print(f'y selected train {y_selected_train.shape}')\n",
    "print(f'y selected test {y_selected_test.shape}')\n",
    "\n",
    "print(f'y selected train {y_selected_train.shape}')\n",
    "print(f'y selected test {y_selected_test.shape}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7067581374981754\n",
      "Testing Score: 0.6900175131348512\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_selected_train_scaled, y_selected_train)\n",
    "print(f'Training Score: {clf.score(X_selected_train_scaled, y_selected_train)}')\n",
    "print(f'Testing Score: {clf.score(X_selected_test_scaled, y_selected_test)}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data going into these models was never scaled, an important step in preprocessing. Use `StandardScaler` to scale the training and testing sets. Before re-fitting the LogisticRegression and RandomForestClassifier models on the scaled data, make another prediction about how you think scaling will affect the accuracy of the models. Write your predictions down and provide justification.\n",
    "\n",
    "Fit and score the LogisticRegression and RandomForestClassifier models on the scaled data. How do the model scores compare to each other, and to the previous results on unscaled data? How does this compare to your prediction? Write down your results and thoughts.\n",
    "\n",
    "\n",
    "The logistic regression worked slightly better than random forest model but not by much."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec8df479c0d1dcc4a6fcdc539b27d2145d9c4f911372971f3a80a17644b4f29d"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 ('PythonData')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
